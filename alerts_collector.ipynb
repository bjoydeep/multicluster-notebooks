{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install prometheus-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prometheus_api_client import *\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "# Set default Seaborn style\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_context(\"talk\", font_scale=1.4)\n",
    "## hides ipython warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.rcParams['figure.figsize'] = (30, 10)\n",
    "#plt.rcParams['figure.figsize'] = (20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting data out of ACM Observability for Offline Analysis :\n",
    "\n",
    "## To set up\n",
    "\n",
    "1. Install ACM and Observability\n",
    "1. Get URL of the route called rbac-query-proxy created in namespace:open-cluster-management-observability\n",
    "1. Get the bearer token of the logged in user\n",
    "1. Select the time range in the cell below\n",
    "\n",
    "## If you run this notebook\n",
    "1. It will create a dataframe in line with the PromQL query and timestamp set\n",
    "1. And dump the data in a csv in the local file system. \n",
    "1. The user will be rbac-ed as per their roles set up in ACM\n",
    "\n",
    "## Note\n",
    "1. We run the analysis of this data in a separate notebook\n",
    "1. However there is nothing stopping us from the doing this analysis inline without saving data in a csv. \n",
    "1. A real data set produced from a run is stored in `data/alert-2.csv`. You can use this data and analyze following instructions on another notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets the connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the route call rbac-query-proxy \n",
    "# created in namespace:open-cluster-management-observability\n",
    "# after installing Observability on Advanaced Cluster Managment Install\n",
    "url = \"https://rbac-query-proxy-open-cluster-management-observability.apps.xyz.redhat.com/\"\n",
    "# bearer token obtained from command `oc whoami -t`\n",
    "token = \"sha256~5AyxhxNb4voPuT0galw4X-abcd1234xyz\"\n",
    "#connects to Thanos or Prometheus as dictated by the URL\n",
    "pc = PrometheusConnect(url=url, headers={\"Authorization\": \"Bearer {}\".format(token)}, disable_ssl=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sets the time range and time step for all queries below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time=(datetime.datetime.now() - datetime.timedelta(minutes=2160))\n",
    "end_time=datetime.datetime.now()\n",
    "#interval between data points gathered\n",
    "step='10m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs Query and Saves data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromQL being run: count(ALERTS{alertstate=\"firing\"}) by (cluster,alertname)\n",
    "alert_total = pc.custom_query_range(\n",
    "    query='count(ALERTS{alertstate=\"firing\"}) by (cluster,alertname)',\n",
    "    start_time=start_time,\n",
    "    end_time=end_time,\n",
    "    step=step,\n",
    ")\n",
    "\n",
    "alert_total_df = MetricRangeDataFrame(alert_total);\n",
    "alert_total_df[\"value\"]=alert_total_df[\"value\"].astype(float)\n",
    "alert_total_df.index= pandas.to_datetime(alert_total_df.index, unit=\"s\")\n",
    "\n",
    "print(alert_total_df.head())\n",
    "print(alert_total_df.count())\n",
    "\n",
    "# Saves the data in path /Users/jbanerje/code/multicluster-notebooks/data/alert-2.csv\n",
    "#alert_total_df.to_csv (r'/Users/jbanerje/code/multicluster-notebooks/data/alert-2.csv', index = True, header=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
